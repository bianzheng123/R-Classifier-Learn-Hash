目前正在做的事情:
1. 正在将批量执行改成单个单个执行
2. 同时数据的检测方式也需要改进

需要做的事情:
1. 实现一整个流程以及框架
2. 将配置文件独立出来, config里面放置模型需要用到的参数


需求: 训练一个模型, 这个模型将R^d空间分成若干个桶
base_model.py
- train()
输入: base的向量
输出: 需要将模型参数保存, 放到文件中
- eval()
输入: query, 需要访问多少个桶
有可能访问桶的个数比这个模型的partition个数大, 这时返回全部元素
输出: 需要的搜索的点的index, 基于0
训练模型, 预测会在哪几个桶中分布

实现流程
首先, 搞出gnd, base, queries
根据配置参数输出化各个模型的, 并对各个模型的进行训练
对各个模型进行评估, 得到每一张图的索引
将索引取交集, 算recall

文件结构
.
    _kahip
    model
    procedure
    util

kmeans参数

- 需要聚类的个数 k

learn-to-hash

- 需要构建knn图 k_graph
- 需要partition的个数 n_clusters
- 图切分时的强度strong......
- 训练时的层数